---
title: >-
  [ReSTIR+SVGF-Sim]Spatiotemporal Reservoir Resampling With Spatiotemporal
  Filtering In MiniEngine
date: 2024-10-01 16:55:05
tags:
---

# Introduction
# [ReSTIR]Spatiotemporal Reservoir Resampling
## Theory

There are two basic problems in the Monte Carlo integration of rendering equation to reduce the errors and improve the sampling efficiency:

1.Given the limited sample number, find a distribution similar to the function f(x) in the integrand, making the samples more likely to be taken when the magnitude of the integrand is relatively large. In orther words, take the samples that are more importance.

2.How to draw random samples from the chosen probability distribution found in problem 1.

It's really hard to take a sample from the PDF that is proportional to {% katex %}L(w_i)f_r(w_i,w_o)cos(\theta_i){% endkatex %} for traditional sampling method (such as inverse sampling)，since it requires us to evaluate the integral at first, which becomes a chicken and egg problem. The sample importance resampling algorithm (SIR) described below solves this problem.

### Sample Importance Resampling (SIR)

#### SIR Workflow
As drawing samples from the target PDF[{% katex %}p_{target}(x){% endkatex %}] proportional to {% katex %}L(w_i)f_r(w_i,w_o)cos(\theta_i){% endkatex %} is hard, SIR takes samples from a more simple PDF called proposal PDF[{% katex %}p_{proposal}(x){% endkatex %}]. Here is the basic workflow of the SIR:

1.Take M samples from proposal PDF [{% katex %}p_{proposal}(x){% endkatex %}], named as [{% katex %}X = x_1, x_2, ..., x_m{% endkatex %}]. 
In our implementation, we use uniform sample hemisphere sampling to generate the samples, which means:
{% katex %}p_{proposal}(x) = \frac{1}{2\pi}{% endkatex %}

2.For each sample taken from {% katex %}X{% endkatex %}, assign a weight for the sample, which is: 
{% katex %}w(x) = \frac{p_{target}(x)}{p_{proposal}(x)}{% endkatex %}. 
And 
{% katex %}p_{target}(x) = luminance(L(w_i)f_r(w_i,w_o)cos(\theta_i)) {%endkatex %}
​
3.Next, draw a sample from {% katex %}X{% endkatex %}, also named as target sample in this post, from this proposal sample set of M. The probability of each sample being picked is proportional to its weight, which means:

{% katex %} p(x_z|X) = \frac{w(x_z)}{\Sigma_{i=0}^{M}w(x_i)} {% endkatex %}. 

The PDF of drawing a sample from the whole sample space is called SIR PDF. 

{% katex %}p_{sir}(x) = \frac{p_{target}(x)}{\frac{1}{M}\Sigma_{i=1}^{M}w(x_{i})}{% endkatex %}

#### [SIR PDF Derivation](https://www.zhihu.com/question/572528081/answer/3540624011)
Suppose the event {% katex %}Ez{% endkatex %} is sample {% katex %}z{% endkatex %} drawn from the sample set {% katex %}X{% endkatex %} and the event {% katex %}EX{% endkatex %} is sample {% katex %}z{% endkatex %} existing in the sample set {% katex %}X{% endkatex %}.
{% katex %}p(Ez | EX) = \frac{p(Ez\cap EX)}{p(EX)}{% endkatex %}
Where 
{% katex %}p(Ez | EX) = p(x_z|X) = \frac{w(x_z)}{\Sigma_{i=0}^{M}w(x_i)}{% endkatex %}<br>
And the SIR PDF is:
{% katex %} p_{sir}(x) = p(Ez\cap EX) {% endkatex %}<br>
{% katex %}p(Ez\cap EX) = p(Ez | EX) p(EX){% endkatex %}
Draw a sample from the whole sample space, the probability of this sample being equal to {% katex %}z{% endkatex %} is {% katex %}p_{proposal}(z){% endkatex %}.  The probability that sample {% katex %}z{% endkatex %} exists in sample set {% katex %}X{% endkatex %} is:
{% katex %}p(EX) = p_{proposal}(z) + ...... + p_{proposal}(z) = p_{proposal}(z)*M{% endkatex %}<br>

Finally
{% katex %} p_{sir}(z) = p(Ez | EX) p(EX) {% endkatex %}<br>
{% katex %} = \frac{w(x_z)}{\Sigma_{i=0}^{M}w(x_i)} p(EX) {% endkatex %}<br>
{% katex %} = \frac{w(x_z)}{\Sigma_{i=0}^{M}w(x_i)} p_{proposal}(z)*M {% endkatex %}<br>
{% katex %} = \frac{p_{target}(z)}{\Sigma_{i=0}^{M}w(x_i)} *M {% endkatex %}<br>
{% katex %} = \frac{p_{target}(z)}{\frac{1}{M}\Sigma_{i=0}^{M}w(x_i)} {% endkatex %}<br>

When {% katex %}M = 1{% endkatex %},

{% katex %} p_{sir}(x) = \frac{p_{target}(x)}{w(x)} = p_{proposal}(z){% endkatex %}<br>

### Resampled Importance Sampling (RIS)

RIS uses importance sampling to draw samples from SIR. It should be noted that the SIR, similar to the inverse mapping, is a sampling distribution mapping instead of importance sampling !!! The RIS workflow is the same as Importance sampling:

1.Generate M samples by SIR as described in the SIR part.
2.Draw N samples from M samples generated by SIR using importance sampling from the SIR distribution.

The integration formula is shown below, which is the same as **importance sampling**:
{% katex %}I_{RIS}^{N,M}=\frac{1}{N}\Sigma_{i=1}^{N}\frac{f(x_{i})}{p_{sir}(x_{i})}{% endkatex %}
Replace the SIR PDF with the formula derived before:
{% katex %}I_{RIS}^{N,M}=\frac{1}{N}\Sigma_{i=1}^{N}\frac{f(x_{i})}{p_{sir}(x_{i})}{% endkatex %}<br>
{% katex %}=\frac{1}{N}\Sigma_{i=1}^{N}(\frac{f(x_{i})}{p_{target}(x)}(\frac{1}{M}\Sigma_{p=0}^{M}w(x_{ip}))){% endkatex %}
When N = 1, it becomes:
{% katex %}I_{RIS}^{1,M}=\frac{f(x_{i})}{p_{target}(x)}(\frac{1}{M}\Sigma_{p=0}^{M}w(x_{ip})){% endkatex %}
,**Which is used in ReSTIR**.

###  Weighted Reservoir Sampling(WRS)

RIS requires us to pick a sample (N = 1) from M proposal samples generated by SIR, which causes two issues:

1.Requires O(M) space for storing proposal samples.
2.The time complexity of picking up a sample is O(M).

>Weighted reservoir sampling is an elegant algorithm that draws a sample from a stream of samples without pre-existed knowledge about how many samples are coming. Each sample in the stream would stand a chance that is proportional to its weight to be picked as the winner.

Assume we have n samples {% katex %}x_i\in[1,n]{% endkatex %}. Each sample weighs {% katex %}w(x_i){% endkatex %} and its probability is {% katex %}p(x_i){% endkatex %}. In ReSTIR, WRS **temporally** iterates the samples in the sample stream, picking and storing a sample randomly with the probability {% katex %}p(x_i){% endkatex %}.

{% katex %}p(x_i)=\frac{w(x_i)}{\Sigma_{j=1}^{n}w(x_j)}{% endkatex %}

According to the above formula, WRS stores two variables:
Current picked sample({% katex %}w(x_i){% endkatex %})
Total processed weight({% katex %}\Sigma_{j=1}^{n}w(x_j){% endkatex %})

#### The Workflow of WRS

Assume we have iterated {% katex %}k-1(k\in[1,n]){% endkatex %}, the iterating result is stored in a structure named reservoir containing the following members:
1.The sample that is picked after (k-1) times of iteration.  {% katex %}y=x_t,t\in[1,k-1]{% endkatex %}
2.The sum of the weight.{% katex %}w_{sum} = \Sigma_{i=1}^{k-1}w(x_i){% endkatex %}

For an incoming sample in iteration k, we perform the following steps:
1.Generate a random number(r) between 0 and 1.
2.If {% katex %}r > \frac{w(x_k)}{w_{sum}+w(x_k)}{% endkatex %}, the incoming sample will be ignored.
3.If {% katex %}r <= \frac{w(x_k)}{w_{sum}+w(x_k)}{% endkatex %}, the new sample will be picked as the winner replacing the previously picked sample, if existed
4.Regardless, the total weight will be updated.{% katex %}w_{sum}=w_{sum}+w(x_k){% endkatex %}

#### Prof of Picking Probability

Assuming K samples have been processed, we want to prove that the probability of picking sample k-1 is satisfied with the probability formula.

If sample K is ignored, the probability of sample K-1 being picked is {% katex %}p_1=\frac{w(x_{k-1})}{\Sigma_{i=1}^{k-1}w(x_i)}{% endkatex %}.
If sample K is picked, the probability of sample K being picked is p1, which means the probability of K-1 being ignored is {% katex %}p_2=\frac{w(x_{k})}{\Sigma_{i=1}^{k}w(x_i)}{% endkatex %}.

The probability of sample K-1 being picked when we process sample K is:
{% katex %}p(x_{k-1}) = p_1 * (1-p_2)= \frac{w(x_{k-1})}{\Sigma_{i=1}^{k-1}w(x_i)} * (1-\frac{w(x_{k})}{\Sigma_{i=1}^{k}w(x_i)}) {% endkatex %}<br>
{% katex %}= \frac{w(x_{k-1})}{\Sigma_{i=1}^{k-1}w(x_i)} * \frac{\Sigma_{i=1}^{k-1}w(x_i)}{\Sigma_{i=1}^{k}w(x_i)} {% endkatex %}<br>
{% katex %}= \frac{w(x_{k-1})}{\Sigma_{i=1}^{k}w(x_i)} {% endkatex %}<br>

## Implementation Detail
### Initial Sample
### Temporal Resampling
### Spatial Resampling

## Advanced
### MIS used with RIS
### Unbias Prof of RIS

# Spatiotemporal Filtering
If you want to dive deeper into SVGF, you can read my Chinese blog.
## Theory
## Implementation Detail